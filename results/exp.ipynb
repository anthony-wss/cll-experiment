{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seeds = {\n",
    "    \"uniform-cifar10\": [0, 2],\n",
    "    \"uniform-cifar20\": [0, 2],\n",
    "    \"clcifar10\": [0, 2, 10],\n",
    "    \"clcifar20\": [0, 2, 10],\n",
    "    \"clcifar10-iid\": [0, 2, 10],\n",
    "    \"clcifar20-iid\": [0, 2, 10],\n",
    "}\n",
    "\n",
    "algos = [\"fwd-u\", \"fwd-r\", \"ure-ga-u\", \"ure-ga-r\", \"scl-nl\", \"scl-exp\", \"l-w\", \"l-uw\", \"pc-sigmoid\"]\n",
    "\n",
    "columns = ['selected by URE', 'URE', 'selected by SCEL', 'SCEL', 'selected by val_acc', 'valid_acc', 'best_ure', 'best_scel', 'best_val_acc']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Uniform CL v.s. CLCIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform-cifar10 2\n",
      "clcifar10 3\n",
      "uniform-cifar20 2\n",
      "clcifar20 3\n",
      "fwd-u     & 48.44\\scriptsize{$\\pm$0.97}     & 49.33\\scriptsize{$\\pm$0.07}         & 34.09\\scriptsize{$\\pm$1.16} & 36.83\\scriptsize{$\\pm$1.17}     & 17.4\\scriptsize{$\\pm$4.12}     & 17.97\\scriptsize{$\\pm$2.69}         & 7.47\\scriptsize{$\\pm$0.37}  & 8.27\\scriptsize{$\\pm$0.77}      \\\\\n",
      "fwd-r     & \\textbf{nan\\scriptsize{$\\pm$nan}}     & \\textbf{nan\\scriptsize{$\\pm$nan}}         & 28.88\\scriptsize{$\\pm$0.65} & \\textbf{38.9\\scriptsize{$\\pm$1.57}}     & \\textbf{nan\\scriptsize{$\\pm$nan}}     & \\textbf{nan\\scriptsize{$\\pm$nan}}         & \\textbf{16.14\\scriptsize{$\\pm$1.11}}  & \\textbf{20.31\\scriptsize{$\\pm$0.25}}      \\\\\n",
      "ure-ga-u     & 39.55\\scriptsize{$\\pm$0.06}     & 39.67\\scriptsize{$\\pm$0.11}         & \\textbf{34.59\\scriptsize{$\\pm$0.76}} & 36.39\\scriptsize{$\\pm$0.67}     & 13.52\\scriptsize{$\\pm$2.76}     & 14.08\\scriptsize{$\\pm$1.97}         & 7.59\\scriptsize{$\\pm$0.36}  & 10.06\\scriptsize{$\\pm$0.72}      \\\\\n",
      "ure-ga-r     & nan\\scriptsize{$\\pm$nan}     & nan\\scriptsize{$\\pm$nan}         & 28.7\\scriptsize{$\\pm$1.39} & 30.94\\scriptsize{$\\pm$1.66}     & nan\\scriptsize{$\\pm$nan}     & nan\\scriptsize{$\\pm$nan}         & 5.24\\scriptsize{$\\pm$0.2}  & 5.46\\scriptsize{$\\pm$0.28}      \\\\\n",
      "scl-nl     & 48.2\\scriptsize{$\\pm$0.6}     & 48.27\\scriptsize{$\\pm$0.33}         & 33.8\\scriptsize{$\\pm$0.52} & 37.81\\scriptsize{$\\pm$2.12}     & 16.55\\scriptsize{$\\pm$3.35}     & 17.54\\scriptsize{$\\pm$2.85}         & 7.58\\scriptsize{$\\pm$0.66}  & 8.53\\scriptsize{$\\pm$0.29}      \\\\\n",
      "scl-exp     & 46.79\\scriptsize{$\\pm$1.95}     & 47.52\\scriptsize{$\\pm$0.16}         & 34.59\\scriptsize{$\\pm$0.72} & 36.96\\scriptsize{$\\pm$0.18}     & 16.18\\scriptsize{$\\pm$3.68}     & 17.89\\scriptsize{$\\pm$3.87}         & 7.55\\scriptsize{$\\pm$0.51}  & 8.11\\scriptsize{$\\pm$0.71}      \\\\\n",
      "l-w     & 27.02\\scriptsize{$\\pm$1.67}     & 44.78\\scriptsize{$\\pm$1.2}         & 28.04\\scriptsize{$\\pm$0.38} & 34.55\\scriptsize{$\\pm$2.05}     & 10.39\\scriptsize{$\\pm$3.25}     & 16.3\\scriptsize{$\\pm$1.77}         & 7.08\\scriptsize{$\\pm$1.1}  & 8.74\\scriptsize{$\\pm$0.42}      \\\\\n",
      "l-uw     & 31.3\\scriptsize{$\\pm$0.52}     & 46.38\\scriptsize{$\\pm$1.07}         & 30.63\\scriptsize{$\\pm$1.87} & 35.13\\scriptsize{$\\pm$1.56}     & 12.33\\scriptsize{$\\pm$3.3}     & 16.32\\scriptsize{$\\pm$1.17}         & 7.36\\scriptsize{$\\pm$0.33}  & 8.71\\scriptsize{$\\pm$0.31}      \\\\\n",
      "pc-sigmoid     & 18.97\\scriptsize{$\\pm$0.0}     & 33.26\\scriptsize{$\\pm$0.0}         & 24.38\\scriptsize{$\\pm$2.18} & 35.88\\scriptsize{$\\pm$0.98}     & 7.67\\scriptsize{$\\pm$0.0}     & 10.41\\scriptsize{$\\pm$0.0}         & 9.27\\scriptsize{$\\pm$0.37}  & 14.26\\scriptsize{$\\pm$1.04}      \\\\\n"
     ]
    }
   ],
   "source": [
    "# \"selected by val_acc\", \"best_val_acc\" for each algorithm\n",
    "exp1_result = {}\n",
    "\n",
    "for dataset in [\"uniform-cifar10\", \"clcifar10\", \"uniform-cifar20\", \"clcifar20\"]:\n",
    "    df = []\n",
    "    for seed in seeds[dataset]:\n",
    "        df.append(pd.read_csv(f\"{seed}/{dataset}.csv\"))\n",
    "\n",
    "    def reformat(row):\n",
    "        # row['acc'] = f\"{row['mean'].round(2)}\\scriptsize($\\pm${row['std'].round(2)})\"\n",
    "        row['acc'] = str(row['mean'].round(2)) + \"\\scriptsize{$\\pm$\" + str(row['std'].round(2)) + '}'\n",
    "        row = row.drop(['mean', 'std'])\n",
    "        return row\n",
    "    \n",
    "    dataset_df = pd.DataFrame()\n",
    "    for algo in algos:\n",
    "        result = []\n",
    "        for i in range(len(seeds[dataset])):\n",
    "            result.append(df[i].loc[df[i]['algo'] == algo])\n",
    "        if not result:\n",
    "            dataset_df[algo] = \"-\"\n",
    "            continue\n",
    "        if algo == 'pc-sigmoid':\n",
    "            print(dataset, len(result))\n",
    "        res = pd.DataFrame()\n",
    "        res['mean'] = pd.concat(result, axis=0).mean(axis=0, numeric_only=True)\n",
    "        res['std'] = pd.concat(result, axis=0).std(axis=0, numeric_only=True)\n",
    "\n",
    "        res = res.apply(reformat, axis=1).transpose()\n",
    "        dataset_df[algo] = res.loc['acc']\n",
    "    \n",
    "    for row in [\"selected by val_acc\", \"best_val_acc\"]:\n",
    "        acc_list = dataset_df.loc[row].to_list()\n",
    "        max_idx = np.array(list(map(lambda x: 0 if x == '-' else float(x.split('\\\\')[0]), acc_list))).argmax()\n",
    "        # print(np.array(map(lambda x: 0 if x == '-' else float(x.split('\\\\')[0]), acc_list)))\n",
    "        max_idx = algos[max_idx]\n",
    "        dataset_df.at[row, max_idx] = \"\\\\textbf{\" + dataset_df.loc[row, max_idx] + \"}\"\n",
    "\n",
    "    dataset_df = dataset_df.transpose()\n",
    "    dataset_df.drop(['selected by URE', 'URE', 'selected by SCEL', 'SCEL', 'valid_acc', 'best_ure', 'best_scel'], axis=1, inplace=True)\n",
    "    dataset_df.rename(columns={\"selected by val_acc\": \"valid_acc\", \"best_val_acc\": \"valid_acc (ES)\"}, inplace=True)\n",
    "\n",
    "    exp1_result[dataset] = dataset_df\n",
    "    \n",
    "exp1_result = pd.concat(exp1_result, axis=1)\n",
    "# exp1_result\n",
    "for idx, row in exp1_result.iterrows():\n",
    "    row = row.to_list()\n",
    "    print(f\"{idx}     & {row[0]}     & {row[1]}         & {row[2]} & {row[3]}     & {row[4]}     & {row[5]}         & {row[6]}  & {row[7]}      \\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. fwd-r suffers from overfitting on both clcifar10 and clcifar20. It is not the case when T is uniform.\n",
    "2. ure-ga-u turn out to be a robust choice in clcifar20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Overfit Behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"selected by val_acc\", \"best_val_acc\" for each algorithm\n",
    "exp1_5_result = {}\n",
    "df = pd.read_csv(\"overfit/result.csv\")\n",
    "\n",
    "for dataset in [\"clcifar10\", \"clcifar20\"]:\n",
    "\n",
    "    def reformat(row):\n",
    "        row['acc'] = f\"{row['mean'].round(2)}\\scriptsize({row['std'].round(2)})\"\n",
    "        row['acc'] = row['acc'][:row['acc'].index('(')] + '{' + row['acc'][row['acc'].index('('):] + '}'\n",
    "        row = row.drop(['mean', 'std'])\n",
    "        return row\n",
    "    \n",
    "    dataset_df = {}\n",
    "    dataset_df_es = {}\n",
    "    for algo in algos:\n",
    "\n",
    "        algo_df = df.loc[(df['dataset_name'] == dataset) & (df['algo'] == algo)]\n",
    "        # dataset_df[algo] = algo_df.sort_values('valid_acc', ascending=False).iloc[0]\n",
    "        dataset_df[algo] = algo_df.sort_values('valid_acc', ascending=False).iloc[0]['test_acc'] * 100\n",
    "        dataset_df_es[algo] = algo_df.sort_values('best_epoch-valid_acc.valid_acc', ascending=False).iloc[0]['best_epoch-valid_acc.test_acc'] * 100\n",
    "    \n",
    "    # dataset_df = dataset_df.transpose()\n",
    "    # dataset_df_es = dataset_df_es.transpose()\n",
    "    # dataset_df.drop(['selected by URE', 'URE', 'selected by SCEL', 'SCEL', 'valid_acc', 'best_ure', 'best_scel'], axis=1, inplace=True)\n",
    "    # dataset_df.rename(columns={\"selected by val_acc\": \"valid_acc\", \"best_val_acc\": \"valid_acc (ES)\"}, inplace=True)\n",
    "\n",
    "    dataset_df = pd.DataFrame([dataset_df, dataset_df_es], index=[\"valid_acc\", \"valid_acc(ES)\"]).transpose()\n",
    "\n",
    "    exp1_5_result[dataset] = dataset_df\n",
    "    \n",
    "exp1_5_result = pd.concat(exp1_5_result, axis=1)\n",
    "exp1_5_result\n",
    "for idx, row in exp1_5_result.iterrows():\n",
    "    row = row.to_list()\n",
    "    print(f\"{idx} & {round(row[0], 2)} & {round(row[1], 2)} & {round(row[2], 2)} & {round(row[3], 2)} \\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"selected by val_acc\", \"best_val_acc\" for each algorithm\n",
    "exp2_result = {}\n",
    "\n",
    "for dataset in [\"uniform-cifar10\", \"clcifar10\", \"uniform-cifar20\", \"clcifar20\"]:\n",
    "    df = []\n",
    "    for seed in seeds[dataset]:\n",
    "        df.append(pd.read_csv(f\"{seed}/{dataset}.csv\"))\n",
    "\n",
    "    def reformat(row):\n",
    "        row['acc'] = row['mean'].round(2)\n",
    "        row = row.drop(['mean', 'std'])\n",
    "        return row\n",
    "    \n",
    "    def convert_nan(row):\n",
    "        if np.isnan(row['fwd-r']):\n",
    "            row['fwd-r'] = '-'\n",
    "        if np.isnan(row['ure-ga-r']):\n",
    "            row['ure-ga-r'] = '-'\n",
    "    \n",
    "    dataset_df = pd.DataFrame()\n",
    "    for algo in algos:\n",
    "        result = []\n",
    "        for i in range(len(seeds[dataset])):\n",
    "            if i != 0:\n",
    "                result.append(df[i].loc[df[i]['algo'] == algo])\n",
    "            elif algo != 'pc-sigmoid':\n",
    "                result.append(df[i].loc[df[i]['algo'] == algo])\n",
    "        if not result:\n",
    "            dataset_df[algo] = \"-\"\n",
    "            continue\n",
    "        res = pd.DataFrame()\n",
    "        res['mean'] = pd.concat(result, axis=0).mean(axis=0, numeric_only=True)\n",
    "        res['std'] = pd.concat(result, axis=0).std(axis=0, numeric_only=True)\n",
    "        res = res.apply(reformat, axis=1).transpose()\n",
    "\n",
    "        dataset_df[algo] = res.loc['acc']\n",
    "    \n",
    "    \n",
    "    dataset_df = dataset_df.transpose()\n",
    "    dataset_df.drop(['URE', 'SCEL', 'valid_acc', 'best_val_acc', 'valid_acc', \"best_ure\", \"best_scel\"], axis=1, inplace=True)\n",
    "    dataset_df = dataset_df.reindex(columns=[\"selected by URE\", \"selected by SCEL\", \"selected by val_acc\"])\n",
    "    dataset_df = dataset_df.rename(columns={\"selected by URE\": \"URE\", \"selected by SCEL\":\"SCEL\", \"selected by val_acc\":\"valid acc\"})\n",
    "    gap = []\n",
    "    for _, row in dataset_df.iterrows():\n",
    "        gap.append(row['valid acc'] - max(row['URE'], row['SCEL']))\n",
    "    dataset_df['gap'] = gap\n",
    "    dataset_df.apply(convert_nan)\n",
    "\n",
    "    exp2_result[dataset] = dataset_df\n",
    "    \n",
    "exp2_result = pd.concat(exp2_result, axis=1)\n",
    "exp2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fwd-u -1.1 2.17\n",
      "fwd-r -0.36 1.15\n",
      "ure-ga-u -3.03 1.25\n",
      "ure-ga-r 0.74 0.35\n",
      "scl-nl -0.67 1.81\n",
      "scl-exp -1.97 1.16\n",
      "l-w -2.5 0.56\n",
      "l-uw -3.53 1.36\n",
      "pc-sigmoid -2.03 2.05\n"
     ]
    }
   ],
   "source": [
    "exp3_result = {d: {} for d in [\"clcifar10\", \"clcifar10-iid\", \"clcifar20\", \"clcifar20-iid\"]}\n",
    "\n",
    "for dataset in [\"clcifar10\", \"clcifar10-iid\", \"clcifar20\", \"clcifar20-iid\"]:\n",
    "    df = []\n",
    "    for seed in seeds[dataset]:\n",
    "        df.append(pd.read_csv(f\"{seed}/{dataset}.csv\"))\n",
    "\n",
    "    def reformat(row):\n",
    "        # row['acc'] = f\"{row['mean'].round(2)}\\scriptsize({row['std'].round(2)})\"\n",
    "        row['acc'] = str(row['mean'].round(2)) + \"\\scriptsize{$\\pm$\" + str(row['std'].round(2)) + '}'\n",
    "        row = row.drop(['mean', 'std'])\n",
    "        return row\n",
    "    \n",
    "    dataset_df = pd.DataFrame()\n",
    "    for algo in algos:\n",
    "        result = []\n",
    "        for i in range(len(seeds[dataset])):\n",
    "            # if df[i].loc[df[i]['algo'] == algo].shape[0] == 0:\n",
    "            #     break\n",
    "            if i != 0:\n",
    "                result.append(df[i].loc[df[i]['algo'] == algo])\n",
    "            elif algo != 'pc-sigmoid':\n",
    "                result.append(df[i].loc[df[i]['algo'] == algo])\n",
    "        if not result:\n",
    "            dataset_df[algo] = \"-\"\n",
    "            continue\n",
    "        # print(dataset, algo, [r['selected by val_acc'].item() for r in result])\n",
    "        exp3_result[dataset][algo] = [r['selected by val_acc'].item() for r in result]\n",
    "        continue\n",
    "        res = pd.DataFrame()\n",
    "        res['mean'] = pd.concat(result, axis=0).mean(axis=0, numeric_only=True)\n",
    "        res['std'] = pd.concat(result, axis=0).std(axis=0, numeric_only=True)\n",
    "        res = res.apply(reformat, axis=1).transpose()\n",
    "\n",
    "        dataset_df[algo] = res.loc['acc']\n",
    "    \n",
    "    \n",
    "    # dataset_df = dataset_df.transpose()\n",
    "    # dataset_df.drop(['selected by URE', 'URE', 'selected by SCEL', 'SCEL', 'valid_acc', 'best_ure', 'best_scel', \"best_val_acc\"], axis=1, inplace=True)\n",
    "    # dataset_df.rename(columns={\"selected by val_acc\": \"valid_acc\"}, inplace=True)\n",
    "    \n",
    "    # exp3_result[dataset] = dataset_df\n",
    "    \n",
    "# exp3_result = pd.concat(exp3_result, axis=1)\n",
    "exp3_result\n",
    "\n",
    "for algo in algos:\n",
    "    diff = [exp3_result['clcifar10-iid'][algo][i]-exp3_result['clcifar10'][algo][i] for i in range(len(exp3_result['clcifar10'][algo]))]\n",
    "    print(algo, round(np.mean(diff), 2), round(np.std(diff), 2))\n",
    "\n",
    "# for idx, row in exp3_result.iterrows():\n",
    "#     row = row.to_list()\n",
    "#     result_str = f\"{idx}\\t&\\t{row[0]}\\t&\\t{row[1]}\\t&\\t{row[2]}\\t&\\t{row[3]}\\\\\\\\\"\n",
    "#     # result_str = f\"{idx}\" + '\\t& '\n",
    "#     # if float(row[0].split('\\\\')[0]) > float(row[1].split('\\\\')[0]):\n",
    "#     #     result_str += \"\\\\textbf{\" + row[0] + \"}\" + '\\t& ' + row[1] + '\\t& '\n",
    "#     # else:\n",
    "#     #     result_str += row[0] + '\\t& ' + \"\\\\textbf{\" + row[1] + \"}\"+  '\\t& '\n",
    "\n",
    "#     # if float(row[2].split('\\\\')[0]) > float(row[3].split('\\\\')[0]):\n",
    "#     #     result_str += \"\\\\textbf{\" + row[2] + \"}\" + '\\t& ' + row[3] + '\\\\\\\\'\n",
    "#     # else:\n",
    "#     #     result_str += row[2] + '\\t& ' + \"\\\\textbf{\" + row[3] + \"}\"+  '\\\\\\\\'\n",
    "#     print(result_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Different Data Cleaning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data_cleaning/data_cleaning-result.csv\")\n",
    "\n",
    "df['data_cleaning_rate'].value_counts()\n",
    "\n",
    "for dataset in ['clcifar10-noiseless', 'clcifar20-noiseless']:\n",
    "    print(dataset)\n",
    "    for algo in ['fwd-u', 'fwd-r', 'ure-ga-u', 'ure-ga-r']:\n",
    "        result = []\n",
    "        zero_df = pd.read_csv(f\"0/{dataset.split('-')[0]}.csv\")\n",
    "        result.append(round(float(zero_df.loc[(zero_df['algo'] == algo)]['selected by val_acc']), 2))\n",
    "        for rate in [0.25, 0.5, 0.75, 1.0]:\n",
    "            sub_df = df.loc[(df['data_cleaning_rate'] == rate) & (df['algo'] == algo) & (df['dataset_name'] == dataset)]\n",
    "            result.append(round(sub_df.sort_values('valid_acc', ascending=False).iloc[0]['test_acc'] * 100, 2))\n",
    "        print(algo, result)\n",
    "        result = []\n",
    "        result.append(round(float(zero_df.loc[(zero_df['algo'] == algo)]['best_val_acc']), 2))\n",
    "        for rate in [0.25, 0.5, 0.75, 1.0]:\n",
    "            sub_df = df.loc[(df['data_cleaning_rate'] == rate) & (df['algo'] == algo) & (df['dataset_name'] == dataset)]\n",
    "            result.append(round(sub_df.sort_values('best_epoch-valid_acc.valid_acc', ascending=False).iloc[0]['best_epoch-valid_acc.test_acc'] * 100, 2))\n",
    "        print(algo, result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the data\n",
    "fwd_u = [35.43, 39.35, 47.78, 54.5, 64.72]\n",
    "fwd_u_es = [36.97, 39.17, 48.2, 55.51, 64.72]\n",
    "fwd_r = [28.14, 36.23, 37.73, 47.86, 56.47]\n",
    "fwd_r_es = [40.61, 42.88, 47.81, 51.39, 63.03]\n",
    "\n",
    "uniform_clcifar10_fwd = 48.44\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fwd_u, linestyle='solid', marker='o', color='blue', label='fwd-u')\n",
    "ax.plot(fwd_u_es, linestyle='--', marker='^', color='blue', label='fwd-u(ES)')\n",
    "ax.plot(fwd_r, linestyle='solid', marker='o', color='red', label='fwd-r')\n",
    "ax.plot(fwd_r_es, linestyle='--', marker='^', color='red', label='fwd-r(ES)')\n",
    "# ax.axhline(y=uniform_clcifar10_fwd, color='tomato', label='uniform CL')\n",
    "\n",
    "xticks = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "# ax.fill_between(xticks, fwd_u, fwd_u_es, where=fwd_u_es>=fwd_u, interpolate=True, color='gray', alpha=0.3)\n",
    "# ax.fill_between(xticks, y1, y2, where=y2<y1, interpolate=True, color='green', alpha=0.3)\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('Noise Cleaning Rate')\n",
    "\n",
    "ax.set_xticks(range(len(fwd_u)))\n",
    "ax.set_xticklabels(xticks)\n",
    "\n",
    "yticks = list(range(0, 71, 10))\n",
    "ax.set_yticks(yticks)\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig(\"data_cleaning/noise-cleaning-fwd-clcifar10.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the data\n",
    "fwd_u = [7.05, 8.64, 9.46, 10.41, 10.9]\n",
    "fwd_u_es = [7.38, 8.65, 10.31, 10.95, 10.6]\n",
    "fwd_r = [14.96, 16.64, 18.02, 18.27, 19.24]\n",
    "fwd_r_es = [20.23, 21.26, 21.96, 23.77, 24.9]\n",
    "\n",
    "uniform_clcifar20_fwd = 17.4\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fwd_u, linestyle='solid', marker='o', color='blue', label='fwd-u')\n",
    "ax.plot(fwd_u_es, linestyle='--', marker='^', color='blue', label='fwd-u(ES)')\n",
    "ax.plot(fwd_r, linestyle='solid', marker='o', color='red', label='fwd-r')\n",
    "ax.plot(fwd_r_es, linestyle='--', marker='^', color='red', label='fwd-r(ES)')\n",
    "# ax.axhline(y=uniform_clcifar20_fwd, color='tomato', label='uniform CL')\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('Noise Cleaning Rate')\n",
    "\n",
    "xticks = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "ax.set_xticks(range(len(fwd_u)))\n",
    "ax.set_xticklabels(xticks)\n",
    "\n",
    "yticks = list(range(0, 71, 10))\n",
    "ax.set_yticks(yticks)\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig(\"data_cleaning/noise-cleaning-fwd-clcifar20.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Learning with Multiple CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "df = pd.read_csv(\"mcl/mcl_result.csv\")\n",
    "df.loc[(df['algo'] == 'fwd-u') & (df['num_cl'] == 2)]['seed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mcl/mcl_result.csv\")\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for dataset in ['clcifar10-mcl', 'clcifar20-mcl']:\n",
    "    sub_result = pd.DataFrame()\n",
    "    for ncl in [2, 3]:\n",
    "        res_df = {}\n",
    "\n",
    "\n",
    "        for algo in [\"fwd-u\", \"fwd-r\", \"ure-ga-u\", \"ure-ga-r\", \"scl-nl\", \"scl-exp\", \"l-w\", \"l-uw\", \"pc-sigmoid\"]:\n",
    "            df1 = df.loc[(df['num_cl'] == ncl) & (df['dataset_name'] == dataset) & (df['algo'] == algo)]\n",
    "            last_acc = round(df1.sort_values('valid_acc', ascending=False).iloc[0]['test_acc']*100, 2)\n",
    "            early_acc = round(df1.sort_values('best_epoch-valid_acc.valid_acc', ascending=False).iloc[0]['best_epoch-valid_acc.test_acc']*100, 2)\n",
    "            res_df[algo] = f\"{last_acc}\\scriptsize\" + '{' + f\"({early_acc})\" + '} &'\n",
    "        \n",
    "        sub_result[ncl] = res_df\n",
    "    print(dataset)\n",
    "    pprint(sub_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the win/loss rate of URE, SCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['clcifar20-iid', 'clcifar20', 'clcifar10-iid', 'clcifar10']\n",
    "\n",
    "win_rate = {}\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = {'scel':[], 'ure':[], 'tie':[]}\n",
    "\n",
    "def scel_win(acc):\n",
    "    dist['scel'].append(acc)\n",
    "\n",
    "def ure_win(acc):\n",
    "    dist['ure'].append(acc)\n",
    "\n",
    "def tie_win(acc):\n",
    "    dist['tie'].append(acc)\n",
    "\n",
    "results = {}\n",
    "for d in ['clcifar20-iid', 'clcifar20', 'clcifar10-iid', 'clcifar10']:\n",
    "    count_ure, tie, count_scel = 0, 0, 0\n",
    "    es_count_ure, es_tie, es_count_scel = 0, 0, 0\n",
    "    scel_err_dis = []\n",
    "    ure_err_dis = []\n",
    "    es_scel_err_dis = []\n",
    "    es_ure_err_dis = []\n",
    "\n",
    "    scel_success = 0\n",
    "    ure_success = 0\n",
    "    es_scel_success = 0\n",
    "    es_ure_success = 0\n",
    "    for seed in [0, 2, 10]:\n",
    "        df = pd.read_csv(f\"{seed}/wandb_result-{seed}.csv\")\n",
    "\n",
    "        for algo in [\"fwd-u\", \"fwd-r\", \"ure-ga-u\", \"ure-ga-r\", \"scl-nl\", \"scl-exp\", \"l-w\", \"l-uw\"]:\n",
    "\n",
    "            possible_res = df.loc[(df['algo'] == algo) & (df['dataset_name'] == d)]\n",
    "\n",
    "            # last_scel_acc =         possible_res.sort_values('scel').iloc[0]['test_acc']\n",
    "            sub_df = possible_res.sort_values('scel')\n",
    "            sub_df = sub_df.loc[~sub_df['test_acc'].isna()]\n",
    "            last_scel_acc = sub_df.iloc[0]['test_acc']\n",
    "\n",
    "            early_scel_acc =        possible_res.sort_values('best_epoch-scel.scel').iloc[0]['best_epoch-scel.test_acc']\n",
    "            last_ure_acc =          possible_res.sort_values('ure').iloc[0]['test_acc']\n",
    "            early_ure_acc =         possible_res.sort_values('best_epoch-ure.ure').iloc[0]['best_epoch-ure.test_acc']\n",
    "            last_true_label_acc =   possible_res.sort_values('valid_acc', ascending=False).iloc[0]['test_acc']\n",
    "            early_true_label_acc =  possible_res.sort_values('best_epoch-valid_acc.valid_acc', ascending=False).iloc[0]['best_epoch-valid_acc.test_acc']\n",
    "\n",
    "            if d == \"clcifar20\":\n",
    "                print(last_scel_acc)\n",
    "\n",
    "            ure_err_dis.append(last_true_label_acc - last_ure_acc)\n",
    "            scel_err_dis.append(last_true_label_acc - last_scel_acc)\n",
    "            if last_scel_acc == last_true_label_acc:\n",
    "                scel_success += 1\n",
    "            if last_ure_acc == last_true_label_acc:\n",
    "                ure_success += 1\n",
    "            \n",
    "            es_ure_err_dis.append(early_true_label_acc - early_ure_acc)\n",
    "            es_scel_err_dis.append(early_true_label_acc - early_scel_acc)\n",
    "            if early_scel_acc == early_true_label_acc:\n",
    "                es_scel_success += 1\n",
    "            if early_ure_acc == early_true_label_acc:\n",
    "                es_ure_success += 1\n",
    "                \n",
    "    print(d, scel_success/24, ure_success/24, es_scel_success/24, es_ure_success/24)\n",
    "    \n",
    "    scel_result = pd.DataFrame([np.mean(scel_err_dis), np.mean(es_scel_err_dis)], index=['last', 'ES'])\n",
    "    ure_result = pd.DataFrame([np.mean(ure_err_dis), np.mean(es_ure_err_dis)], index=['last', 'ES'])\n",
    "\n",
    "    results[d] = pd.concat([scel_result, ure_result]).transpose()\n",
    "\n",
    "results = pd.concat(results, axis=0, ignore_index=False)\n",
    "results\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter([e[0] for e in ure_err_dis], [e[1] for e in ure_err_dis], color='red')\n",
    "# plt.scatter([e[0] for e in scel_err_dis], [e[1] for e in scel_err_dis], color='green')\n",
    "# plt.show()\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "# axs[0].hist(dist['scel'], bins=30, alpha=0.5, color='green')\n",
    "# axs[0].set_title(\"SCEL win\")\n",
    "\n",
    "# axs[1].hist(dist['tie'], bins=30, alpha=0.5, color='blue')\n",
    "# axs[1].set_title(\"tie\")\n",
    "\n",
    "# axs[2].hist(dist['ure'], bins=30, alpha=0.5, color='red')\n",
    "# axs[2].set_title(\"URE win\")\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to optimal accuracy\n",
    "### Last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['clcifar20-noiseless', 'clcifar20-iid', 'clcifar20-aggregate',\n",
    "           'clcifar20', 'clcifar10-noiseless', 'clcifar10-iid',\n",
    "           'clcifar10-aggregate', 'clcifar10']\n",
    "\n",
    "win_rate = []\n",
    "\n",
    "res = {}\n",
    "for d in datasets:\n",
    "    for seed in [2, 10]:\n",
    "        df = pd.read_csv(f\"{seed}/wandb_result-{seed}.csv\")\n",
    "\n",
    "        dis = []\n",
    "        for algo in [\"fwd-u\", \"fwd-r\", \"ure-ga-u\", \"ure-ga-r\", \"scl-nl\", \"scl-exp\", \"l-w\", \"l-uw\"]:\n",
    "\n",
    "            possible_res = df.loc[(df['algo'] == algo) & (df['dataset_name'] == d)]\n",
    "            dis.append(possible_res.sort_values('valid_acc', ascending=False).iloc[0]['test_acc'] - possible_res.sort_values('scel').iloc[0]['test_acc'])\n",
    "            \n",
    "        res[d] = round(np.mean(dis) * 100, 2)\n",
    "win_rate.append(res)\n",
    "\n",
    "res = {}\n",
    "for d in datasets:\n",
    "    for seed in [2, 10]:\n",
    "        df = pd.read_csv(f\"{seed}/wandb_result-{seed}.csv\")\n",
    "\n",
    "        dis = []\n",
    "        for algo in [\"fwd-u\", \"fwd-r\", \"ure-ga-u\", \"ure-ga-r\", \"scl-nl\", \"scl-exp\", \"l-w\", \"l-uw\"]:\n",
    "\n",
    "            possible_res = df.loc[(df['algo'] == algo) & (df['dataset_name'] == d)]\n",
    "            dis.append(possible_res.sort_values('valid_acc', ascending=False).iloc[0]['test_acc'] - possible_res.sort_values('ure').iloc[0]['test_acc'])\n",
    "            \n",
    "        res[d] = round(np.mean(dis) * 100, 2)\n",
    "win_rate.append(res)\n",
    "        \n",
    "win_rate = pd.DataFrame(win_rate, index=['|scel - test_acc|', '|ure - test_acc|'])\n",
    "win_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "1. The difference between URE and SCEL is small ( ~ 1%)\n",
    "2. The distance to valid_acc is dataset dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['clcifar20-noiseless', 'clcifar20-iid', 'clcifar20-aggregate',\n",
    "           'clcifar20', 'clcifar10-noiseless', 'clcifar10-iid',\n",
    "           'clcifar10-aggregate', 'clcifar10']\n",
    "\n",
    "win_rate = []\n",
    "\n",
    "res = {}\n",
    "for d in datasets:\n",
    "    for seed in [2, 10]:\n",
    "        df = pd.read_csv(f\"{seed}/wandb_result-{seed}.csv\")\n",
    "\n",
    "        dis = []\n",
    "        for algo in [\"fwd-u\", \"fwd-r\", \"ure-ga-u\", \"ure-ga-r\", \"scl-nl\", \"scl-exp\", \"l-w\", \"l-uw\"]:\n",
    "\n",
    "            possible_res = df.loc[(df['algo'] == algo) & (df['dataset_name'] == d)]\n",
    "            dis.append(possible_res.sort_values('best_epoch-valid_acc.valid_acc', ascending=False).iloc[0]['best_epoch-valid_acc.test_acc'] - possible_res.sort_values('best_epoch-scel.scel').iloc[0]['best_epoch-scel.test_acc'])\n",
    "            \n",
    "        res[d] = round(np.mean(dis) * 100, 2)\n",
    "win_rate.append(res)\n",
    "\n",
    "res = {}\n",
    "for d in datasets:\n",
    "    for seed in [2, 10]:\n",
    "        df = pd.read_csv(f\"{seed}/wandb_result-{seed}.csv\")\n",
    "\n",
    "        dis = []\n",
    "        for algo in [\"fwd-u\", \"fwd-r\", \"ure-ga-u\", \"ure-ga-r\", \"scl-nl\", \"scl-exp\", \"l-w\", \"l-uw\"]:\n",
    "\n",
    "            possible_res = df.loc[(df['algo'] == algo) & (df['dataset_name'] == d)]\n",
    "            dis.append(possible_res.sort_values('best_epoch-valid_acc.valid_acc', ascending=False).iloc[0]['best_epoch-valid_acc.test_acc'] - possible_res.sort_values('best_epoch-ure.ure').iloc[0]['best_epoch-ure.test_acc'])\n",
    "            \n",
    "        res[d] = round(np.mean(dis) * 100, 2)\n",
    "win_rate.append(res)\n",
    "        \n",
    "win_rate = pd.DataFrame(win_rate, index=['|scel - test_acc|', '|ure - test_acc|'])\n",
    "win_rate\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
